\section{Methods}
\label{sec:methods}
% NOT finished

% \subsection{The Challenge Database}
% \label{subsec:database}
% % finished

% The challenge database \cite{Oliveira_2021_CirCor} provides multiple PCG recordings collected at different auscultation locations for a number of young subjects. The annotations of the existence of heart murmurs are provided for each recording, along with annotations for heart sound segmentation annotation. The clinical outcomes are provided for each subject. For algorithm development, we divided the public subset of the challenge database into the training set and the validation set with a ratio of 8:2. This split was stratified on the categorical attributes ``Age'', ``Sex'', ``Pregnancy status'' and the prediction targets ``Murmur'', ``Outcome''.


\subsection{Preprocess Pipeline}
\label{subsec:preproc}
% finished

After a careful study of spectral characteristics of heart murmurs from medical literature \cite{Noponen_2007}, and with reference to previous work \cite{Schmidt_2010}, we constructed the PCG signal preprocessing pipeline as follows:
\begin{itemize}
    \item Resample to 1000 Hz;
    \item Butterworth bandpass filtering of order 3 and cutoff frequencies 25 - 400 Hz;
    \item Z-score normalization to zero mean and unit variance.
\end{itemize}

\subsection{Neural Network Backbones}
\label{subsec:backbone}
% finished

Inspired by the work of wav2vec2 \cite{baevski2020wav2vec}, and under the consideration of exploring and utilizing the powerfulness of pretraining models on larger databases, we adopted a shrunken \texttt{wav2vec2} as one of our neural network backbones. We used the time-domain signals, namely the PCG waveforms, as model input, rather than the derived time-frequency-domain signals, for example, the spectrogram. Since PCGs have significantly lower sampling rates than conventional human voice audio signals, we reduced the dimension (number of channels) of the `wav2vec2` model's encoder and its depth (number of hidden layers).

% The `wav2vec2` model has a small block of convolutions in the bottom used as the feature extractor which extracts feature maps of a fixed dimension from the waveforms and feeds into ...

\input{tables/nn_backbones.tex}

Considering that PCG signals share a similar physiological origin as electrocardiogram (ECG) signals, we further adjusted and tested several neural network backbones that have proven effective in ECG problems, including multi-branch convolutional neural networks (MultiBranch), SE-ResNet, TResNetS, TResNetF \cite{Kang_2022_cinc2021_iop}, and ResNet-NC \cite{ribeiro2020automatic} etc. We enlarged the kernel sizes of each convolution in these backbones by a factor of 2, which is the ratio of the sampling frequencies.

The efficacy of most of the neural network backbones is validated via experiments as illustrated in Figure \ref{fig:compare_nn}. The learning process of the wav2vec2 model was interrupted at an early stage. The cause for this abnormal phenomenon is left for further studies.

\input{plot_figures/compare_nn.tex}

\subsection{Multi-Task Learning}
\label{subsec:mtl}
% finished

The challenge \cite{cinc2022} has 2 per-patient classification tasks:
\begin{itemize}
    \item the prediction of the existence of heart murmurs into 3 classes: ``Present'', ``Unknown'', ``Absent'';
    \item the prediction of clinical outcome of the subject into 2 classes: ``Abnormal'', ``Normal''.
\end{itemize}

It should be noted that the challenge database \cite{Oliveira_2021_CirCor} provides per-recording annotations for the former task and heart sound segmentation annotations as well. We applied the multi-task learning (MTL) paradigm \cite{Caruana_1997_mtl} via hard parameter sharing. More precisely, we use one neural network model for all the tasks. Each task has its specific model head, typically a stack of linear layers concatenated to the shared backbone as discussed in Section \ref{subsec:backbone}. Our MTL paradigm is illustrated in Figure \ref{fig:mtl_paradigm}.

\input{plot_figures/mtl_paradigm.tex}

As depicted in Figure \ref{fig:mtl_comparison}, experiments showed that models (with the same backbone) using an additional segmentation head (denoted as ``MTL3'') usually outperformed models with only two classification heads (denoted as ``MTL2'') for the challenge tasks.

\input{plot_figures/mtl_comparison.tex}

\subsection{Training Setups}
\label{subsec:training}
% NOT finished


For algorithm development, we divided the publicly available part of the challenge database into the training set and the validation set with a ratio of 8:2. This split was stratified on the attributes ``Age'', ``Sex'', ``Pregnancy status'' and the prediction targets ``Murmur'', ``Outcome''.

The batch size was set at 32 for model training, with the maximum number of epochs set at 60. Model parameters were optimized using the AMSGrad variant of the AdamW optimizer along with the \texttt{OneCycle} scheduler. We froze the backbone from a specific epoch (usually 30).

To alleviate overfitting on the training set, the early stopping callback was added. To further improve model transferability, we applied several types of augmentations to the batched training data stochastically:
\begin{itemize}
    \item adding coloured noises;
    \item polarity inversion (flipping).
\end{itemize}

We experimented with two types of loss functions: the asymmetric loss (denoted ``Loss-A''); the weighted binary cross entropy (denoted ``Loss-B''). The weights were obtained from the weight matrix of the challenge scoring functions \cite{cinc2022}. The superiority of Loss-B was observed, as was illustrated in Figure \ref{fig:clf-se-resnet-lossA-vs-lossB}.

\input{plot_figures/loss.tex}

\subsection{Demographic Features}
\label{subsec:demo_feat}
% NOT finished

\begin{figure}[!htp]
\centering
\begin{subfigure}[b]{0.49\linewidth}
    \centering
    \includegraphics[width=\textwidth]{images/outcome_murmur_corr.pdf}
    \caption[]
    {Distribution of outcome against the existence of heart murmurs.}
    \label{fig:outcome_murmur_corr}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.49\linewidth}
    \centering
    \includegraphics[width=\textwidth]{images/outcome_pregnancy_status_corr.pdf}
    \caption[]
    {Distribution of outcome against pregnancy status.}
    \label{fig:outcome_pregnancy_status_corr}
\end{subfigure}
\vskip\baselineskip
\begin{subfigure}[b]{0.49\linewidth}
    \centering
    \includegraphics[width=\textwidth]{images/outcome_age_corr.pdf}
    \caption[]
    {Distribution of outcome against age.}
    \label{fig:outcome_age_corr}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.49\linewidth}
    \centering
    \includegraphics[width=\textwidth]{images/outcome_sex_corr.pdf}
    \caption[]
    {Distribution of outcome against sex.}
    \label{fig:outcome_sex_corr}
\end{subfigure}
\caption[]
{Distribution of outcome against 4 typical categorical demographic variables.}
\label{fig:outcome_corr}
\end{figure}
