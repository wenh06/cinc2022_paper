\section{Discussion and Conclusions}
\label{sec:discu}
% finished.

Our MTL paradigm proved effective for the problems of heart murmur detection and clinical outcome identification from PCGs in this study. The rankings of our team on the hidden validation and on the whole public training set were 20 / 40, 26 / 40 for murmur weighted accuracy, and 21 / 39, 32 / 39 for outcome cost respectively. These were all significantly lower than our rankings on the hidden test set as listed in Table \ref{tab:challenge_scores}. This phenomenon is not surprising, since the MLT paradigm has already shown to have the ability to improve generalizability via leveraging latent domain-specific knowledge inherited in the training data of related tasks \cite{Caruana_1997_mtl}. As for the problems that the Challenge raised, the additional segmentation head makes the shared representation (the common backbone) learn more general features and thus improves the performances for the original two classification tasks (heads).

The convolutional neural backbones also proved their effectiveness as has already shown in Figure \ref{fig:compare_nn}. Indeed, this figure exhibits only a small part of the architectures we had experimented with. However, there is still room for improvement, as compared to the top teams on the Challenge leaderboard.

One regret of this study is that the potential of using derived time-frequency-domain signals is not explored. Previous studies on various physiological signals have shown the powerfulness of neural networks combining the derived time-frequency-domain signals with the original time-domain signals.

Another weakness of this work is that we failed to use the wav2vec2 model for tackling the Challenge problems. One possible reason is that transformer-based models need to be trained on larger datasets, and perform worse on smaller datasets than CNNs. Using larger datasets to perform self-supervised pretraining for PCGs would be a direction for our future work.
